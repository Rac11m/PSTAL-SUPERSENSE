{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a2dd35dd-14a6-4ee5-b369-5d46635b0200",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from conllu import parse_incr\n",
    "from collections import defaultdict\n",
    "\n",
    "def load_corpus(in_file):\n",
    "    sents = parse_incr(open(in_file, encoding='UTF-8'))\n",
    "    word_sent = {}\n",
    "    upos_sent = {}\n",
    "    for i, sent in enumerate(sents):\n",
    "        word_sent[i] = []\n",
    "        upos_sent[i] = []\n",
    "        for token in sent:\n",
    "            word_sent[i].append(token[\"form\"])\n",
    "            upos_sent[i].append(token[\"upos\"]) \n",
    "        \n",
    "    return word_sent, upos_sent\n",
    "\n",
    "def token_alignment(input_sent, input_upos, tok_sent, emb_sent):\n",
    "    '''\n",
    "    input_sent: from conllu corpus, pair of (word,upos) \n",
    "    tok_sent: from the tokenizer of the pre-trained model\n",
    "    '''\n",
    "    # VALID_UPOS = [ADJ, ADP, ADV, AUX, CCONJ, DET, INTJ, NOUN, NUM, PART, PRON, PROPN, PUNCT, SCONJ, SYM, VERB, X]\n",
    "    VALID_UPOS = [\"NOUN\", \"NUM\", \"PROPN\"]\n",
    "    \n",
    "    np_tok_sent = np.array(tok_sent.word_ids()) # convert the list of tokens to numpy array to use the np.where function\n",
    "    tok_alignment = dict() # create en defaultdict contraining the ids corresponding to the word in tok_sent\n",
    "    for id, w in enumerate(input_sent): \n",
    "        if (input_upos[id]).upper() in VALID_UPOS:\n",
    "            tok_alignment[id] = (np.where(np_tok_sent == id)[0]).tolist()\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    # get embedding of each word\n",
    "    word_emb = dict.fromkeys(tok_alignment.keys(),None)\n",
    "    for word, tok in tok_alignment.items():    \n",
    "        word_emb[word] = emb_sent[tok].mean(dim=0)\n",
    "    \n",
    "    return tok_alignment, word_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "0fe64ca7-44f7-4bfa-b569-285db0b28af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question: \n",
    "### Why no RNN is this Lab? ===> Answer: Contextuel embeddings \n",
    "### Why using the mean? ===> Answer: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa96204a-67b7-4de8-9e7f-4f0a0e98bc5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sent, upos_sent = load_corpus(\"../pstal-etu/sequoia/sequoia-ud.parseme.frsemcor.simple.small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dcadccc3-c1d1-4b81-855b-6a230ab4993c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([47, 768])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "tokenize = AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-multilingual-cased\")\n",
    "tok_sent = tokenize(input_sent[0], is_split_into_words=True, return_tensors='pt')\n",
    "\n",
    "model = AutoModel.from_pretrained(\"distilbert/distilbert-base-multilingual-cased\")\n",
    "with torch.no_grad():    \n",
    "    emb_sent = model(**tok_sent)['last_hidden_state'][0]\n",
    "print(emb_sent.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b673453-4c21-4fd5-ba3b-d11ef0d04341",
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_alignment, emb_alignment = dict(), dict()\n",
    "for idx, (sent, upos) in enumerate(zip(input_sent.items(), upos_sent.items())):\n",
    "    tok_alignment[idx], emb_alignment[idx] = token_alignment(sent[1], upos[1], tok_sent, emb_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5cf2c41b-460d-4ab7-94d1-019e339d6d0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([1, 5, 9, 12, 16, 19, 22, 23, 25, 29, 31])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_alignment[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8a3b76be-e039-471d-a12a-ddb702407db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pairs(in_file, emb_alignment):\n",
    "    pairs = []\n",
    "    for i, sent in enumerate(parse_incr(open(in_file, encoding='UTF-8'))):\n",
    "        for idx, tok in enumerate(sent):   \n",
    "            if tok[\"upos\"] in [\"NOUN\", \"NUM\", \"PROPN\"]:\n",
    "                pairs.append((emb_alignment[i][idx], tok[\"frsemcor:noun\"]))\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "704ef9aa-a93f-4e3f-b5b0-5bdd9d85cff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_file = \"../pstal-etu/sequoia/sequoia-ud.parseme.frsemcor.simple.small\"\n",
    "\n",
    "pairs = get_pairs(in_file, emb_alignment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4f7862af-cb47-4159-9325-388853b50a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader(dataset, batch_size, shuffle_mode):\n",
    "    from torch.utils.data import DataLoader\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=shuffle_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "91da7c60-e9ae-4a8f-b820-74cb39cfc02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = create_dataloader(pairs, 32, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c95e7d51-f63c-4ccd-a48b-4716800ff045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([47, 768])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "tokenize = AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-multilingual-cased\")\n",
    "tok_sent = tokenize(input_sent[0], is_split_into_words=True, return_tensors='pt')\n",
    "\n",
    "model = AutoModel.from_pretrained(\"distilbert/distilbert-base-multilingual-cased\")\n",
    "with torch.no_grad():    \n",
    "    emb_sent = model(**tok_sent)['last_hidden_state'][0]\n",
    "print(emb_sent.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ac9a207d-0a2d-4c64-9ab2-0a7bbae61eea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.hidden_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a418124c-3e29-4816-8bbe-ce53520437fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sense_values = set()\n",
    "for i, sent in enumerate(parse_incr(open(\"../pstal-etu/sequoia/sequoia-ud.parseme.frsemcor.simple.full\", encoding='UTF-8'))):\n",
    "    for idx, tok in enumerate(sent):   \n",
    "        sense_values.add(tok[\"frsemcor:noun\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0c45c51f-e7b5-4174-a26e-d67e21c316f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Feeling',\n",
       " 'Cognition',\n",
       " 'Relation',\n",
       " 'Artifact',\n",
       " 'Group',\n",
       " 'Phenomenon',\n",
       " 'Quantity',\n",
       " 'Part',\n",
       " 'Substance',\n",
       " 'Body',\n",
       " 'Person',\n",
       " 'Food',\n",
       " 'Animal',\n",
       " 'Communication',\n",
       " 'Act',\n",
       " 'Object',\n",
       " 'Institution',\n",
       " 'Attribute',\n",
       " 'Plant',\n",
       " 'Possession',\n",
       " 'Time',\n",
       " 'Tops',\n",
       " '*',\n",
       " 'State',\n",
       " 'Event']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(sense_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d5fe71a6-cfdb-47b0-9137-c55bd722d14c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(list(sense_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1338f279-67a2-49cf-8548-946835caf201",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertConfig {\n",
       "  \"activation\": \"gelu\",\n",
       "  \"architectures\": [\n",
       "    \"DistilBertForMaskedLM\"\n",
       "  ],\n",
       "  \"attention_dropout\": 0.1,\n",
       "  \"dim\": 768,\n",
       "  \"dropout\": 0.1,\n",
       "  \"dtype\": \"float32\",\n",
       "  \"hidden_dim\": 3072,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"distilbert\",\n",
       "  \"n_heads\": 12,\n",
       "  \"n_layers\": 6,\n",
       "  \"output_past\": true,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"qa_dropout\": 0.1,\n",
       "  \"seq_classif_dropout\": 0.2,\n",
       "  \"sinusoidal_pos_embds\": false,\n",
       "  \"tie_weights_\": true,\n",
       "  \"transformers_version\": \"4.57.3\",\n",
       "  \"vocab_size\": 119547\n",
       "}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f5b0d0-34bc-49db-b7aa-46b165d5411f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
