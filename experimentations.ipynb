{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "344a169d-e8f9-4089-af1b-3902390cf9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "tokenize = AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-multilingual-cased\")\n",
    "tok_sent = tokenize([\"Arturo\",\"devra\",\"retenter\",\"demain\"], is_split_into_words=True, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d6c38671-fb49-4323-943f-b552d7623897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  101, 33141, 10104, 39210, 32641, 25446, 10268, 18073,   102]])\n"
     ]
    }
   ],
   "source": [
    "print(tok_sent['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b44285e9-41cd-4ff1-acac-bae2b750c405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([9, 768])\n"
     ]
    }
   ],
   "source": [
    "model = AutoModel.from_pretrained(\"distilbert/distilbert-base-multilingual-cased\")\n",
    "with torch.no_grad():    \n",
    "    emb_sent = model(**tok_sent)['last_hidden_state'][0]\n",
    "print(emb_sent.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a5e8c2a1-c1ee-4ded-a6c4-60de95a690b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "def token_alignment(input_sent, tok_sent, upos_filter):\n",
    "    '''\n",
    "    input_sent: from corpus, raw sentence\n",
    "    tok_sent: from the tokenizer of the pre-trained model\n",
    "    '''\n",
    "    np_tok_sent = np.array(tok_sent.word_ids()) # convert the list of tokens to numpy array to use the np.where function\n",
    "    tok_alignment = dict() # create en defaultdict contraining the ids corresponding to the word in tok_sent\n",
    "    for id, w in enumerate(input_sent): \n",
    "        if upos_filter is None:\n",
    "        if upos_filter in \n",
    "        tok_alignment[id] = (np.where(np_tok_sent == id)[0]).tolist() # for loop to store the ids for the tokens corresponding to the word\n",
    "    return tok_alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e925a703-8839-4817-ace0-db127c06ef41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tok_alignment = token_alignment(input_sent, tok_sent)\n",
    "# for k,v in tok_alignment.items():\n",
    "#     print(input_sent[k])\n",
    "#     for i in v:\n",
    "#         print(tok_sent.word_ids()[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "a2dd35dd-14a6-4ee5-b369-5d46635b0200",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "trouver le(s) embedding(s) correspondants à l’aide de word_ids. Créez ensuite un seul\n",
    "embedding pour ce mot en moyennant les embeddings contextuels de ses sub-tokens. Cet embedding sera\n",
    "associé à l’étiquette super-sense du mot. \n",
    "'''\n",
    "from conllu import parse_incr\n",
    "\n",
    "def load_corpus(in_file):\n",
    "    sents = parse_incr(open(in_file, encoding='UTF-8'))\n",
    "    word_sent = {}\n",
    "    upos_sent = {}\n",
    "    for i, sent in enumerate(sents):\n",
    "        word_sent[i] = []\n",
    "        upos_sent[i] = []\n",
    "        for token in sent:\n",
    "            word_sent[i].append(token[\"form\"])\n",
    "            upos_sent[i].append(token[\"upos\"]) \n",
    "        \n",
    "    \n",
    "    return word_sent, upos_sent\n",
    "\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "def token_alignment(input_sent, input_upos, tok_sent, emb_sent):\n",
    "    '''\n",
    "    input_sent: from conllu corpus, pair of (word,upos) \n",
    "    tok_sent: from the tokenizer of the pre-trained model\n",
    "    '''\n",
    "    # VALID_UPOS = [ADJ, ADP, ADV, AUX, CCONJ, DET, INTJ, NOUN, NUM, PART, PRON, PROPN, PUNCT, SCONJ, SYM, VERB, X]\n",
    "    VALID_UPOS = [\"NOUN\", \"NUM\", \"PROPN\"]\n",
    "    \n",
    "    np_tok_sent = np.array(tok_sent.word_ids()) # convert the list of tokens to numpy array to use the np.where function\n",
    "    tok_alignment = dict() # create en defaultdict contraining the ids corresponding to the word in tok_sent\n",
    "    if upos_filter is None:\n",
    "        for id, w in enumerate(input_sent): \n",
    "            tok_alignment[id] = (np.where(np_tok_sent == id)[0]).tolist() # for loop to store the ids for the tokens corresponding to the word\n",
    "    else:\n",
    "        for id, w in enumerate(input_sent): \n",
    "            if (input_upos[id]).upper() in VALID_UPOS:\n",
    "                tok_alignment[id] = (np.where(np_tok_sent == id)[0]).tolist()\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "    # get embedding of each word\n",
    "    word_emb = dict.fromkeys(tok_alignment.keys(),None)\n",
    "    for word, tok in tok_alignment.items():    \n",
    "        word_emb[word] = emb_sent[tok].mean(dim=0)\n",
    "    \n",
    "    return tok_alignment, word_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "0fe64ca7-44f7-4bfa-b569-285db0b28af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question: \n",
    "### Why no RNN is this Lab? ===> Answer: Contextuel embeddings \n",
    "### Why using the mean? ===> Answer: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "fa96204a-67b7-4de8-9e7f-4f0a0e98bc5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sent, upos_sent = load_corpus(\"../PSTAL-MORPHtagging/pstal-etu/sequoia/sequoia-ud.parseme.frsemcor.simple.small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "dcadccc3-c1d1-4b81-855b-6a230ab4993c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([47, 768])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "tokenize = AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-multilingual-cased\")\n",
    "tok_sent = tokenize(input_sent[0], is_split_into_words=True, return_tensors='pt')\n",
    "\n",
    "model = AutoModel.from_pretrained(\"distilbert/distilbert-base-multilingual-cased\")\n",
    "with torch.no_grad():    \n",
    "    emb_sent = model(**tok_sent)['last_hidden_state'][0]\n",
    "print(emb_sent.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "1b673453-4c21-4fd5-ba3b-d11ef0d04341",
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_alignment, emb_alignment = dict(), dict()\n",
    "for idx, (sent, upos) in enumerate(zip(input_sent.items(), upos_sent.items())):\n",
    "    tok_alignment[idx], emb_alignment[idx] = token_alignment(sent[1], upos[1], tok_sent, emb_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "5cf2c41b-460d-4ab7-94d1-019e339d6d0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([1, 5, 9, 12, 16, 19, 22, 23, 25, 29, 31])"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_alignment[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "07049991-03f7-473a-a01e-81d8ecd9b253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# emb_alignment[0][9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "8a3b76be-e039-471d-a12a-ddb702407db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_pairs(emb_alignment, ):\n",
    "in_file = \"../PSTAL-MORPHtagging/pstal-etu/sequoia/sequoia-ud.parseme.frsemcor.simple.small\"\n",
    "pairs = []\n",
    "for i, sent in enumerate(parse_incr(open(in_file, encoding='UTF-8'))):\n",
    "    for idx, tok in enumerate(sent):   \n",
    "        if tok[\"upos\"] in [\"NOUN\", \"NUM\", \"PROPN\"]:\n",
    "            pairs.append((emb_alignment[i][idx], tok[\"frsemcor:noun\"]))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "c30bad17-d777-41ae-879b-08e554ce392b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 2.4548e-02, -3.2410e-01,  6.6246e-01,  3.7163e-01, -5.6628e-02,\n",
       "         -2.4369e-01, -4.9498e-01,  7.4060e-01, -7.5084e-01,  6.2616e-01,\n",
       "         -3.4168e-02,  3.4419e-02, -5.5544e-01,  3.7847e-01, -2.1963e-01,\n",
       "         -3.7520e-01,  4.0847e-01, -2.4299e-01,  2.0511e-03, -3.3328e-01,\n",
       "         -3.5438e-01, -4.1518e-02,  2.1685e-01,  1.3224e-01,  8.6031e-03,\n",
       "          9.5864e-02, -5.0794e-01, -1.3520e-01, -1.1673e-01, -8.2052e-01,\n",
       "          3.4336e-01, -2.4322e-01, -2.8327e-01,  1.1261e+00,  7.0449e-01,\n",
       "          2.4583e-01, -1.8570e-02, -2.3374e-02,  2.8395e-01,  6.2698e-02,\n",
       "          2.3254e-01,  3.2569e-01, -4.4565e-01, -2.0823e-01,  1.1893e-01,\n",
       "         -4.5199e-01,  2.8266e-01, -7.1197e-01,  5.8547e-01,  1.0857e+00,\n",
       "         -1.0936e+00, -1.4291e-01,  1.7317e-01,  1.4788e-01, -2.6592e-01,\n",
       "          9.7784e-02, -5.6060e-01,  1.4198e-01,  1.8125e-01, -7.0146e-01,\n",
       "          6.4720e-01, -2.6596e-01,  7.1156e-01, -4.2304e-01, -4.6336e-01,\n",
       "         -4.3222e-01,  1.3419e-01, -4.9742e-01,  3.5411e-01, -5.6282e-01,\n",
       "         -6.7208e-01,  4.7151e-01,  2.2056e-01,  8.2759e-02, -6.0396e-01,\n",
       "          4.4254e-01,  9.5528e-01,  5.8138e-01, -1.7678e-01,  1.7522e-01,\n",
       "          1.5911e-01,  4.4807e-01,  6.4173e-01,  6.1636e-01, -4.2932e-01,\n",
       "          3.9616e-01,  2.9108e-01, -1.6390e-01,  5.5613e-01, -4.2930e-01,\n",
       "          2.1635e-01, -3.3809e-01, -6.2157e-01, -2.9449e-01, -6.0241e-02,\n",
       "          6.8016e-01, -1.6876e-01, -6.9915e-02, -1.6714e-01,  6.2211e-02,\n",
       "          5.3215e-01,  7.8366e-02,  1.0871e+00, -2.0764e-01,  1.3844e+00,\n",
       "         -3.7299e-01, -2.9149e-01,  1.3853e-01,  3.5429e-02,  4.1669e-01,\n",
       "          1.4662e-01, -4.5188e-01,  2.3816e-01,  3.0768e-01,  6.7660e-01,\n",
       "         -5.8176e-01, -3.5870e-01,  6.5656e-01,  5.0412e-01, -9.5515e-01,\n",
       "          1.5839e-01,  2.3608e-01, -1.3825e-01,  2.6746e-01, -2.3862e-01,\n",
       "         -6.6734e-01, -1.9860e-01, -1.3417e-01,  4.7666e-01,  1.9165e-01,\n",
       "         -3.7954e-01, -3.7353e-01,  1.0985e-02, -9.4304e-02,  3.1745e-01,\n",
       "         -2.7542e-01,  2.7056e-01, -1.1163e-01, -5.5457e-01, -4.0680e-01,\n",
       "         -2.9024e-02,  2.7618e-01,  2.5865e-01,  5.7264e-02,  1.2315e-01,\n",
       "          6.4735e-02, -1.1407e+00,  8.0040e-01,  6.3332e-01, -4.2134e-01,\n",
       "         -3.9587e-02,  2.2690e-01,  8.0295e-02, -9.3963e-02, -3.3818e-01,\n",
       "         -2.1344e-01,  9.8266e-02, -1.8800e-01, -5.8548e-01,  3.3096e-01,\n",
       "          4.7953e-01,  3.7109e-02, -8.7834e-01,  9.1151e-01,  1.1879e-02,\n",
       "         -5.4573e-02, -1.2138e-01,  3.2880e-01,  2.8238e-01,  2.2769e-01,\n",
       "         -8.5289e-01, -2.2290e-01, -3.2167e-01,  2.6258e-01, -7.7813e-02,\n",
       "          1.3012e-01, -4.0160e-02,  1.6325e-01,  4.8123e-02,  2.9202e-01,\n",
       "         -7.0053e-02,  1.7469e-01,  4.9151e-01, -9.1849e-02, -1.5261e-01,\n",
       "          4.6031e-01,  1.7094e-01, -9.0173e-02,  1.2069e-02, -8.0167e-01,\n",
       "          2.8945e-02, -3.0148e-01,  3.9286e-01,  2.3450e-01,  7.6277e-02,\n",
       "          3.2481e-01, -2.3969e-01,  2.2900e-01,  6.4992e-01,  2.2295e-01,\n",
       "         -9.1889e-01, -2.7131e-01, -3.0997e-01, -3.9548e-01, -1.5557e-01,\n",
       "          5.1152e-01,  2.8441e-01, -5.1515e-01, -2.7864e-01, -2.8877e-01,\n",
       "         -7.2973e-01, -4.2408e-01,  3.1368e-01, -3.2062e-01,  1.6930e-01,\n",
       "         -1.1770e-01, -1.1064e-01, -2.4088e-01,  5.8983e-01,  3.1111e-01,\n",
       "          2.4996e-01, -6.9147e-01,  4.9438e-01, -5.0191e-01, -2.6166e-01,\n",
       "         -4.4834e-01, -2.3623e-01,  2.0500e-01,  1.7348e-01, -8.6169e-01,\n",
       "         -2.8615e-01, -4.7056e-01, -2.0882e-01,  2.3120e-01, -6.5375e-02,\n",
       "         -2.0996e-01, -4.2599e-01, -2.7927e-02,  5.6978e-01,  3.8716e-01,\n",
       "          2.2675e-01, -7.6292e-01,  1.8921e-01,  3.3484e-01,  2.8006e-01,\n",
       "          7.6540e-02,  3.1356e-03, -1.4217e-01,  2.5797e-01, -4.0418e-01,\n",
       "          1.5794e-01,  1.0049e-01, -1.6558e-01, -7.3585e-01, -3.4040e-02,\n",
       "          8.5655e-01, -3.7075e-01,  4.5565e-02,  2.8119e-01, -5.9590e-01,\n",
       "          7.4385e-02, -1.3092e-01,  7.0586e-02, -1.3167e-01, -4.0520e-01,\n",
       "          2.2769e-01,  3.0545e-01,  7.0226e-01, -1.7376e-01, -1.0823e-01,\n",
       "          8.6902e-01,  4.3310e-01,  4.5497e-01,  4.8012e-01,  6.5785e-01,\n",
       "          1.3760e-01,  2.8424e-01,  7.9436e-02, -2.0523e-01, -3.4277e-03,\n",
       "          2.7977e-01, -1.3964e-02,  4.5992e-01,  7.5783e-01,  1.3677e-01,\n",
       "         -7.0819e-02, -1.8037e-01,  3.7624e-01, -6.3456e-01, -4.6106e-01,\n",
       "          3.3317e-01, -3.9998e-01,  3.6038e-01,  2.4552e-01,  4.4448e-01,\n",
       "         -3.1658e-01,  1.2715e-01, -1.1149e-01, -5.2838e-01,  1.4119e-01,\n",
       "         -5.1532e-01,  3.1666e-01, -1.9377e-01,  5.0793e-01, -7.2481e-02,\n",
       "          2.5855e-01,  6.1917e-02, -1.1715e+00,  1.0200e+00,  1.1709e-01,\n",
       "         -4.7079e-01,  1.1828e+00, -4.5165e-01, -8.5637e-02,  2.2265e-02,\n",
       "         -1.2568e-01,  7.9391e-01,  1.9508e-01, -1.6199e-01,  1.6849e-01,\n",
       "         -3.0571e-01,  8.2483e-01,  6.0092e-01,  2.3516e-01, -6.2710e-01,\n",
       "          8.7941e-01, -3.2997e-01, -4.1443e-01,  9.3651e-02, -4.2624e-01,\n",
       "          2.6195e-01,  6.2259e-01, -1.3399e-01, -8.7046e-02, -2.1212e-02,\n",
       "         -3.4557e-02,  3.1466e-01,  2.5029e-01, -1.3752e-01,  3.0630e-01,\n",
       "          1.4269e-01, -3.1482e-01,  1.1850e+00,  6.6649e-01, -3.9404e-01,\n",
       "         -4.2165e-02,  5.8733e-01, -7.9991e-01, -4.1334e-01, -4.7734e-02,\n",
       "          1.3216e-01, -3.5579e-02, -5.2669e-02,  3.7757e-02, -3.7932e-01,\n",
       "          3.6533e-01, -8.9076e-01, -1.5610e-01,  3.3386e-01,  3.5134e-01,\n",
       "         -2.2363e-01,  6.5195e-01, -9.3475e-02,  3.8351e-01,  1.0819e-01,\n",
       "         -3.2800e-01, -6.3859e-01, -8.1001e-02,  2.9285e-01,  4.4160e-01,\n",
       "         -1.7870e-01,  4.0837e-01,  7.1032e-02, -6.0550e-01,  5.1214e-01,\n",
       "         -8.2742e-02, -6.1380e-01, -1.4316e-03,  4.5064e-01, -2.7746e-01,\n",
       "          1.0209e+00, -2.8612e-02,  4.4914e-01,  1.4574e-01, -2.5973e-01,\n",
       "         -1.1636e-01,  2.3408e-01,  5.3424e-02, -2.6093e-02, -6.2331e-01,\n",
       "         -1.8128e-01, -2.8801e-01,  5.3045e-01,  2.5161e-01, -1.4512e-01,\n",
       "          1.0724e+00,  1.6216e-01, -2.9562e-01, -3.6246e-01,  1.4862e-02,\n",
       "          1.3458e-01, -3.5978e-01,  2.4710e-01,  4.3448e-01,  6.3268e-01,\n",
       "         -7.9551e-02,  5.8039e-01,  1.0716e-01,  2.7375e-01, -2.3916e-01,\n",
       "         -2.4725e-01,  4.2998e-01,  3.9378e-01,  6.0721e-01, -2.5973e-01,\n",
       "          3.4219e-01, -3.7299e-01, -8.7781e-02, -1.0544e-01,  4.3106e-01,\n",
       "         -6.8017e-02, -2.5241e-01, -5.4664e-01, -1.2773e+00, -8.0239e-01,\n",
       "         -3.5237e-02,  7.4368e-02, -2.4188e-01,  1.1566e-01, -3.3248e-01,\n",
       "         -9.0938e-01, -4.2531e-01,  8.6319e-01, -3.9588e-01, -7.5911e-02,\n",
       "          1.4924e-01, -1.7302e-01, -7.7460e-02,  9.3333e-02,  7.2665e-04,\n",
       "         -2.6855e-01,  4.4296e-01,  2.9989e-01, -3.9095e-01, -2.7518e-01,\n",
       "          4.8362e-01,  1.6301e-01, -3.2022e-01, -3.5955e-01,  3.5905e-01,\n",
       "          6.5124e-01,  9.6429e-02, -5.5587e-01, -2.9052e-03, -8.1693e-02,\n",
       "         -7.2359e-01, -3.7426e-01, -4.2607e-01, -2.1048e-01, -5.9558e-01,\n",
       "          4.8350e-01,  5.2020e-01,  3.5508e-01, -2.4032e-02,  2.4384e-01,\n",
       "         -9.6428e-01,  4.0479e-02, -4.9429e-01,  1.0766e-01,  9.0619e-01,\n",
       "         -2.5826e-01,  2.6733e-01, -7.1456e-01, -3.2353e-01, -1.9409e-01,\n",
       "         -2.0640e-01,  4.7336e-01,  1.6705e-01,  4.8812e-01, -2.4136e-01,\n",
       "          1.2225e-01,  1.3888e-02,  3.1721e-02, -3.9925e-01, -3.2531e-03,\n",
       "          1.1516e-01, -1.0875e-01,  7.1238e-01,  7.3505e-01, -5.1857e-01,\n",
       "         -6.3780e-02,  6.1774e-02,  1.0179e-01, -1.1661e+00, -6.4750e-01,\n",
       "          1.0670e-01,  7.4273e-02, -3.2963e-01,  1.4185e+00, -2.9827e-01,\n",
       "         -6.3692e-02,  7.1567e-01,  4.2121e-01,  3.2072e-02, -1.5476e-01,\n",
       "         -2.0865e-01, -3.1358e-01,  1.6719e-02, -1.5401e-01, -2.5837e-01,\n",
       "          2.2246e-01, -1.7043e+00,  1.8784e-01,  6.5484e-01,  1.3650e-01,\n",
       "          9.0157e-02, -5.3137e-01, -1.1224e-01,  2.9214e-01, -6.7901e-02,\n",
       "         -3.6512e-01, -2.8701e-01,  9.2284e-01, -3.6045e-02, -7.1377e-01,\n",
       "         -4.6611e-01, -5.7961e-03, -8.1634e-01, -1.4136e-02, -2.5063e-01,\n",
       "         -5.3537e-01,  4.0658e-01, -6.9203e-01,  4.5079e-01,  4.4743e-01,\n",
       "         -4.2899e-02, -4.2888e-01, -4.1136e-01, -7.2532e-01,  3.1579e-01,\n",
       "         -1.3305e-01,  1.5032e-01, -4.5373e-02,  1.9515e-01,  1.7028e-01,\n",
       "          5.2855e-01,  5.3569e-01,  3.4567e-01,  1.0780e+00,  9.0273e-01,\n",
       "         -9.5345e-02, -2.6102e-01,  2.3871e-01,  2.7259e-01,  4.9951e-01,\n",
       "          3.1064e-01, -9.0002e-02,  3.6828e-01, -1.7847e-01,  1.2349e-01,\n",
       "          2.9400e-01,  3.6190e-01, -3.3410e-01, -1.2692e-01, -4.0534e-01,\n",
       "          2.5345e-01, -5.9293e-02, -3.7041e-02, -6.4267e-01,  4.3496e-01,\n",
       "          5.0269e-01,  5.9334e-02, -6.4137e-01, -2.0306e-01,  2.6106e-01,\n",
       "          1.3335e-01, -8.6207e-01,  1.4195e-01, -7.6676e-01, -5.2777e-01,\n",
       "         -4.2818e-01, -7.4480e-02, -1.5896e-01,  3.7843e-01,  2.9819e-01,\n",
       "         -3.5530e-01, -4.3533e-01,  2.0296e-01, -4.6418e-01, -5.0661e-02,\n",
       "          1.3187e-01, -8.6927e-04, -1.6860e-01, -6.0001e-02, -1.6726e-01,\n",
       "          8.1474e-01,  1.0668e+00, -2.8675e-01, -1.0556e-01, -5.1189e-01,\n",
       "         -4.5319e-01, -6.7198e-01, -1.5051e-01, -3.7326e-01, -8.9080e-01,\n",
       "         -1.2737e-01,  7.1249e-01,  1.9978e-01,  1.8189e-01, -7.4953e-01,\n",
       "         -1.7100e-01, -3.0037e-01, -7.4448e-01, -2.2009e-03, -4.0757e-01,\n",
       "         -4.4870e-01,  1.0451e-01, -8.1416e-02,  4.1351e-01,  9.8077e-01,\n",
       "         -4.9694e-01,  6.3083e-01,  5.9547e-01,  9.0551e-02, -7.3349e-01,\n",
       "         -3.4465e-01,  2.9834e-01, -3.6363e-01,  8.9949e-01, -2.1186e-01,\n",
       "         -3.3886e-01, -6.9465e-01,  1.4102e-01,  2.8705e-01,  2.8529e-01,\n",
       "         -4.3746e-02,  1.6356e-01, -1.6142e-01, -6.9005e-02,  1.8812e-01,\n",
       "         -3.3363e-01,  3.1706e-01, -2.0308e-01,  3.7244e-02, -3.2202e-02,\n",
       "          6.3761e-01, -1.2231e-02,  5.1181e-02,  2.9642e-01, -1.8051e-02,\n",
       "         -1.2443e-01,  2.9197e-01,  6.5514e-02,  5.0188e-03, -1.7775e-01,\n",
       "          5.1003e-01,  2.4608e-01,  3.5207e-01, -4.3699e-01,  6.1527e-01,\n",
       "          1.2364e-01,  3.7242e-02,  4.9883e-01,  5.3522e-02, -6.6275e-02,\n",
       "          2.0319e-01, -1.2289e+00,  4.6603e-02, -3.3827e-02,  7.0914e-01,\n",
       "         -2.1150e-01, -2.8814e-01,  2.9875e-01, -4.5215e-01,  2.9035e-01,\n",
       "          6.3716e-01,  1.9583e-01,  4.5375e-01,  2.4388e-01, -2.4573e-01,\n",
       "          2.1497e-01, -5.9005e-01,  4.3669e-01,  2.3882e-01, -4.9427e-02,\n",
       "         -3.3814e-01, -5.9530e-01,  3.7311e-01, -3.3076e-02,  2.2470e-01,\n",
       "         -4.1862e-01,  2.5589e-02, -4.9051e-01,  5.1696e-02,  4.8123e-01,\n",
       "          5.3775e-01,  5.6869e-01, -4.0388e-02,  5.0582e-02,  4.8863e-01,\n",
       "         -1.4787e-01, -7.2674e-02,  2.8891e-01, -2.0305e-01,  2.2482e-01,\n",
       "         -5.4259e-01,  3.8058e-01, -8.2953e-01,  1.2274e-01, -1.2605e-01,\n",
       "          2.3726e-01,  1.0014e-01, -2.3451e-01, -3.9104e-01, -2.6983e-01,\n",
       "          3.4917e-02, -1.5815e-01, -2.4161e-01, -1.2267e-02,  2.6999e-01,\n",
       "          3.7054e-01, -4.0582e-02, -3.0968e-02, -5.6801e-01, -1.0743e-01,\n",
       "         -4.9802e-02, -9.3890e-01,  2.4566e-01,  1.4798e-01,  1.7142e-01,\n",
       "         -6.3307e-01, -4.0132e-01,  1.4597e-01, -4.3270e-01,  9.9758e-02,\n",
       "         -1.0980e-01, -2.4016e-01, -2.9533e-01,  1.5500e-01, -1.4771e-01,\n",
       "          1.4390e-01, -1.8965e-01,  1.7890e-01, -2.8513e-01,  6.6421e-01,\n",
       "          5.1020e-01, -2.3841e-01, -1.3782e-01, -3.1522e-01, -4.6387e-01,\n",
       "         -3.9359e-01, -5.9474e-02, -2.9796e-01,  1.7559e-01, -2.0034e-01,\n",
       "         -1.7094e-01, -8.2974e-01,  7.1975e-01, -5.9782e-01, -3.4174e-01,\n",
       "         -8.3868e-01, -3.5608e-01, -2.7301e-01, -1.8593e-01,  2.0015e-01,\n",
       "          2.8876e-01,  1.1158e-01, -3.1692e-02]),\n",
       " 'Institution')"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704ef9aa-a93f-4e3f-b5b0-5bdd9d85cff2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
